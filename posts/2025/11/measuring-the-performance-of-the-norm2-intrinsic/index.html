<!doctype html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
<title>Measuring the performance of the norm2-intrinsic&nbsp;|&nbsp;Ivan Pribec</title>
<meta
  name="title"
  content="Measuring the performance of the norm2-intrinsic"
/>
<meta
  name="description"
  content="A couple months ago, Jean-Christophe Loiseau from Art et Métiers Institute of Technology published a very nice article about speeding-up the Jacobi method in Fortran using multi-threading.
If you are interested in Fortran or you&rsquo;re a student in scientific computing, I can highly recommend reading it.
One thing that piqued my interest in the blog was the following sentence,

Either way [of computing the two-norm] is fine, norm2 is an intrinsic Fortran function and its implementation has already been optimized by the compiler vendors anyway."
/>
<meta
  name="keywords"
  content="Fortran,Performance,norm2,SIMD,"
/>

  <meta name="author" content="Ivan Pribec" />




<meta property="og:url" content="/posts/2025/11/measuring-the-performance-of-the-norm2-intrinsic/">
  <meta property="og:site_name" content="Ivan Pribec">
  <meta property="og:title" content="Measuring the performance of the norm2-intrinsic">
  <meta property="og:description" content="A couple months ago, Jean-Christophe Loiseau from Art et Métiers Institute of Technology published a very nice article about speeding-up the Jacobi method in Fortran using multi-threading. If you are interested in Fortran or you’re a student in scientific computing, I can highly recommend reading it.
One thing that piqued my interest in the blog was the following sentence,
Either way [of computing the two-norm] is fine, norm2 is an intrinsic Fortran function and its implementation has already been optimized by the compiler vendors anyway.">
  <meta property="og:locale" content="en_us">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2025-11-23T00:00:00+01:00">
    <meta property="article:modified_time" content="2025-11-23T00:00:00+01:00">
    <meta property="article:tag" content="Fortran">
    <meta property="article:tag" content="Performance">
    <meta property="article:tag" content="Norm2">
    <meta property="article:tag" content="SIMD">





  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="Measuring the performance of the norm2-intrinsic">
  <meta name="twitter:description" content="A couple months ago, Jean-Christophe Loiseau from Art et Métiers Institute of Technology published a very nice article about speeding-up the Jacobi method in Fortran using multi-threading. If you are interested in Fortran or you’re a student in scientific computing, I can highly recommend reading it.
One thing that piqued my interest in the blog was the following sentence,
Either way [of computing the two-norm] is fine, norm2 is an intrinsic Fortran function and its implementation has already been optimized by the compiler vendors anyway.">





  <meta itemprop="name" content="Measuring the performance of the norm2-intrinsic">
  <meta itemprop="description" content="A couple months ago, Jean-Christophe Loiseau from Art et Métiers Institute of Technology published a very nice article about speeding-up the Jacobi method in Fortran using multi-threading. If you are interested in Fortran or you’re a student in scientific computing, I can highly recommend reading it.
One thing that piqued my interest in the blog was the following sentence,
Either way [of computing the two-norm] is fine, norm2 is an intrinsic Fortran function and its implementation has already been optimized by the compiler vendors anyway.">
  <meta itemprop="datePublished" content="2025-11-23T00:00:00+01:00">
  <meta itemprop="dateModified" content="2025-11-23T00:00:00+01:00">
  <meta itemprop="wordCount" content="859">
  <meta itemprop="keywords" content="Fortran,Performance,Norm2,SIMD">
<meta name="referrer" content="no-referrer-when-downgrade" />

    
    
    
    <link href="/bundle.min.css" rel="stylesheet" />

    

    


    
</head>

  <body>
    <header>
      <nav>
  <a
    href="/"
    
    >home</a
  >

  <a
    href="/posts/"
    
    >blog</a
  >

  <a
    href="/code/"
    
    >code</a
  >

  <a
    href="/diary/"
    
    >diary</a
  >

  <a
    href="/now/"
    
    >now</a
  >


</nav>
    <h1>Measuring the performance of the norm2-intrinsic</h1>


    </header>
    <main>
      
  
  
    
      <p>
        <i>
          <time
            style="color: var(--text-light);"
            datetime="2025-11-23"
            pubdate
          >
            2025-11-23
          </time>
        </i>
      </p>
    
  
  
  <content>
    <p>A couple months ago, Jean-Christophe Loiseau from Art et Métiers Institute of Technology published a <a href="https://loiseaujc.github.io/posts/blog-title/jacobi_experiments.html">very nice article</a> about speeding-up the Jacobi method in Fortran using multi-threading.
If you are interested in Fortran or you&rsquo;re a student in scientific computing, I can highly recommend reading it.</p>
<p>One thing that piqued my interest in the blog was the following sentence,</p>
<blockquote>
<p>Either way [of computing the two-norm] is fine, <code>norm2</code> is an intrinsic Fortran function and its implementation has already been optimized by the compiler vendors anyway.</p>
</blockquote>
<p>The two ways which are discussed are using the intrinsic function, i.e. <code>norm2(u - v)</code>, or using a <code>do concurrent</code> loop construct:</p>






<div class="highlight"><pre tabindex="0" style="color:#4c4f69;background-color:#eff1f5;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-fortran" data-lang="fortran"><span style="display:flex;"><span>	<span style="color:#8839ef">real</span>(dp) <span style="color:#d20f39">::</span> l2_norm
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    l2_norm <span style="color:#04a5e5;font-weight:bold">=</span> <span style="color:#fe640b">0.0_dp</span>
</span></span><span style="display:flex;"><span>    <span style="color:#8839ef">do</span> <span style="color:#8839ef">concurrent</span>(i<span style="color:#04a5e5;font-weight:bold">=</span><span style="color:#fe640b">2</span>:nx<span style="color:#04a5e5;font-weight:bold">-</span><span style="color:#fe640b">1</span>, j<span style="color:#04a5e5;font-weight:bold">=</span><span style="color:#fe640b">2</span>:ny<span style="color:#04a5e5;font-weight:bold">-</span><span style="color:#fe640b">1</span>) reduce(<span style="color:#04a5e5;font-weight:bold">+</span>:l2_norm)
</span></span><span style="display:flex;"><span>        l2_norm <span style="color:#04a5e5;font-weight:bold">=</span> l2_norm <span style="color:#04a5e5;font-weight:bold">+</span> (u(i, j) <span style="color:#04a5e5;font-weight:bold">-</span> v(i, j))<span style="color:#04a5e5;font-weight:bold">**</span><span style="color:#fe640b">2</span>
</span></span><span style="display:flex;"><span>    <span style="color:#8839ef">enddo</span>
</span></span><span style="display:flex;"><span>    l2_norm <span style="color:#04a5e5;font-weight:bold">=</span> <span style="color:#04a5e5">sqrt</span>(l2_norm)</span></span></code></pre></div>
<p>In the past I&rsquo;ve noticed that despite their built-in status, intrinsic functions are not always optimized to the degree you thought they would be. Hager and Wellein summarize this nicely when they say</p>
<blockquote>
<p>It must be understood that compilers can be surprisingly smart and stupid at the same time.
A common statement in discussions about compiler capabilities is &ldquo;The compiler be able to figure that out.&rdquo;
This is often enough a false assumtion.</p>
</blockquote>
<p>At this point I must say that writing an accurate <code>norm2</code> function without undue underflows or overflows is surprisingly hard work.
I won&rsquo;t go into details about the different algorithms, you can peruse the links in the reference section below if you want to.</p>
<p>Instead, we&rsquo;ll be looking at the performance of the &ldquo;simple loop&rdquo; algorithm, expressed using different language constructs. For simplicity we&rsquo;ll look at the two-norm of an array of size 2000^2 (roughly 30.5 MB) filled with random values.</p>
<p>Before we start looking at different Fortran implementations, let&rsquo;s select some performance baselines.
Besides the <code>norm2</code> intrinsic function introduces in Fortran 2008, we can also measure the <code>DNRM2</code> functions that are provided in different BLAS libraries.
For more variety I&rsquo;ve also prepared a 2-norm function using the Eigen C++ library:</p>






<div class="highlight"><pre tabindex="0" style="color:#4c4f69;background-color:#eff1f5;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cxx" data-lang="cxx"><span style="display:flex;"><span><span style="color:#9ca0b0;font-style:italic">#include</span> <span style="color:#9ca0b0;font-weight:bold;font-style:italic">&lt;Eigen/Dense&gt;</span><span style="color:#9ca0b0;font-style:italic">
</span></span></span><span style="display:flex;"><span><span style="color:#9ca0b0;font-style:italic"></span>
</span></span><span style="display:flex;"><span><span style="color:#8839ef">extern</span> <span style="color:#40a02b">&#34;C&#34;</span> <span style="color:#d20f39">double</span> norm2_eigen(<span style="color:#d20f39">int</span> n, <span style="color:#8839ef">const</span> <span style="color:#d20f39">double</span> <span style="color:#04a5e5;font-weight:bold">*</span>x)
</span></span><span style="display:flex;"><span>{
</span></span><span style="display:flex;"><span>	assert(n <span style="color:#04a5e5;font-weight:bold">&gt;=</span> <span style="color:#fe640b">0</span>);
</span></span><span style="display:flex;"><span>    <span style="color:#8839ef">if</span> (n <span style="color:#04a5e5;font-weight:bold">==</span> <span style="color:#fe640b">0</span> <span style="color:#04a5e5;font-weight:bold">||</span> x <span style="color:#04a5e5;font-weight:bold">==</span> <span style="color:#8839ef">nullptr</span>)
</span></span><span style="display:flex;"><span>        <span style="color:#8839ef">return</span> <span style="color:#fe640b">0.0</span>;
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    Eigen<span style="color:#04a5e5;font-weight:bold">::</span>Map<span style="color:#04a5e5;font-weight:bold">&lt;</span><span style="color:#8839ef">const</span> Eigen<span style="color:#04a5e5;font-weight:bold">::</span>VectorXd<span style="color:#04a5e5;font-weight:bold">&gt;</span> v(x, n);
</span></span><span style="display:flex;"><span>    <span style="color:#8839ef">return</span> v.norm();
</span></span><span style="display:flex;"><span>}</span></span></code></pre></div>
<p>For the tests below I&rsquo;ll be using an Apple M2 Pro CPU.
I&rsquo;m using gfortran 15.2 as my main Fortran compiler and the preinstalled Apple clang 17 compiler for C++.</p>
<table>
  <thead>
      <tr>
          <th>Library</th>
          <th>Elapsed (ms)</th>
          <th>Bandwidth (GB/s)</th>
          <th>Different bits</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td><code>norm2</code></td>
          <td>4.9</td>
          <td>6.1</td>
          <td>5</td>
      </tr>
      <tr>
          <td><code>norm2_eigen</code></td>
          <td>0.89</td>
          <td>33.1</td>
          <td>2</td>
      </tr>
      <tr>
          <td>Apple Accelerate</td>
          <td>1.2</td>
          <td>22.5</td>
          <td>2</td>
      </tr>
      <tr>
          <td>OpenBLAS</td>
          <td>4.9</td>
          <td>6.0</td>
          <td>4</td>
      </tr>
      <tr>
          <td>ArmPL</td>
          <td>2.4</td>
          <td>12.2</td>
          <td>3</td>
      </tr>
  </tbody>
</table>
<p>As we can see from the table above, there is quite a spread in the results.
This might be due to the use of different algorithms, but also due to quality of the generated code.
The use of different algorithms, or as it may be simply, different order of evaluation,
can be inferred from the number of different bits compared to a value computed using quadruple precision:</p>






<div class="highlight"><pre tabindex="0" style="color:#4c4f69;background-color:#eff1f5;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-fortran" data-lang="fortran"><span style="display:flex;"><span><span style="color:#8839ef">integer</span>, <span style="color:#8839ef">parameter</span> <span style="color:#d20f39">::</span> qp <span style="color:#04a5e5;font-weight:bold">=</span> <span style="color:#04a5e5">selected_real_kind</span>(<span style="color:#fe640b">32</span>)
</span></span><span style="display:flex;"><span><span style="color:#8839ef">real</span>(dp) <span style="color:#d20f39">::</span> r0
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>r0 <span style="color:#04a5e5;font-weight:bold">=</span> <span style="color:#04a5e5">norm2</span>(<span style="color:#8839ef">real</span>(u,<span style="color:#04a5e5">kind</span><span style="color:#04a5e5;font-weight:bold">=</span>qp))</span></span></code></pre></div>
<p>Note that the Fortran standard only requires <code>norm2</code> to return a <em>processor-dependent</em>
approximation of the 2-norm. (In Fortran jargon, processor is the name of the compiler or interpreter.)</p>
<p>What to make of these results? Is this the top performance which can be reached?
Assuming the naive simple loop algorithm,</p>






<div class="highlight"><pre tabindex="0" style="color:#4c4f69;background-color:#eff1f5;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-fortran" data-lang="fortran"><span style="display:flex;"><span><span style="color:#8839ef">do</span> i <span style="color:#04a5e5;font-weight:bold">=</span> <span style="color:#fe640b">1</span>, n
</span></span><span style="display:flex;"><span>	nrm <span style="color:#04a5e5;font-weight:bold">=</span> nrm <span style="color:#04a5e5;font-weight:bold">+</span> u(i)<span style="color:#04a5e5;font-weight:bold">**</span><span style="color:#fe640b">2</span>
</span></span><span style="display:flex;"><span><span style="color:#8839ef">end</span> <span style="color:#8839ef">do</span>
</span></span><span style="display:flex;"><span>nrm <span style="color:#04a5e5;font-weight:bold">=</span> <span style="color:#04a5e5">sqrt</span>(nrm)</span></span></code></pre></div>
<p>this operation tends to be memory intensive.
For each new element loaded we perform two operations (one addition and one multiplication).
Assuming 64-bit doubles, this gives a code balance of 4 bytes / flop.</p>
<h2 id="unrolling-and-wide">Unrolling and wide</h2>
<p class="notice">
  <em>Comment:</em> one downside of <code>DNRM2</code> is it assumed the input is a contiguous 1-d vector.
This means if want to only calculate the two-norm over the interior region the compiler will probably perform copy-in/copy-out.
</p>

<p>Maybe you know the phrase: &ldquo;Never look a gift hourse in the mouth&rdquo;.
At the end of the day, we should all be grateful to have awesome compilers like gfortran and flang.</p>
<p>Since compilers evolve over time, remember to take these results with a grain of salt.
Maybe the compiler of the future you are using has already solved some of these issues, at least I strongly wish so.</p>
<h2 id="references">References</h2>
<ul>
<li><a href="https://doi.org/10.1145/355769.355771">Blue, J. L. (1978). A portable Fortran program to find the Euclidean norm of a vector. ACM Transactions on Mathematical Software (TOMS), 4(1), 15-23.</a></li>
<li><a href="https://doi.org/10.1145/3134441">Hanson, R. J., &amp; Hopkins, T. (2017). Remark on algorithm 539: A modern Fortran reference implementation for carefully computing the Euclidean norm. ACM Transactions on Mathematical Software (TOMS), 44(3), 1-23.</a></li>
<li><a href="https://doi.org/10.1145/3061665">Anderson, E. (2017). Algorithm 978: Safe scaling in the level 1 BLAS. ACM Transactions on Mathematical Software (TOMS), 44(1), 1-28.</a></li>
</ul>
<p>There are also newer works investigating the use of double-word arithmetic:</p>
<ul>
<li><a href="https://doi.org/10.1007/978-3-030-86653-2_7">Harayama, T., Kudo, S., Mukunoki, D., Imamura, T., &amp; Takahashi, D. (2021, September). A Rapid Euclidean Norm Calculation Algorithm that Reduces Overflow and Underflow. In International Conference on Computational Science and Its Applications (pp. 95-110). Cham: Springer International Publishing.</a></li>
<li><a href="https://doi.org/10.1145/3568672">Lefèvre, V., Louvet, N., Muller, J. M., Picot, J., &amp; Rideau, L. (2023). Accurate calculation of Euclidean norms using double-word arithmetic. ACM Transactions on Mathematical Software, 49(1), 1-34.</a></li>
</ul>

  </content>
  
    
    
      <p>
        
          <a href="/tags/fortran/">#Fortran</a>&nbsp;&nbsp;
        
          <a href="/tags/performance/">#Performance</a>&nbsp;&nbsp;
        
          <a href="/tags/norm2/">#Norm2</a>&nbsp;&nbsp;
        
          <a href="/tags/simd/">#SIMD</a>&nbsp;&nbsp;
        
      </p>
    
    
    
      <div class="flex-between" style="margin-top: 3rem;">
        
          <a href="/posts/2025/11/is-the-humble-for-loop-a-good-way-to-search-an-array/" rel="prev" aria-label="Previous post: Is the Humble For-Loop a Good Way to Search an Array?">
            <span>←</span>
            <span>Is the Humble For-Loop a Good Way to Search an Array?</span>
          </a>
        
        
      </div>
    
  

    </main>
    <footer>
      

      
  <span>© 2025 — Ivan Pribec — All rights reserved.</span>



    </footer>

    
</body>
</html>
